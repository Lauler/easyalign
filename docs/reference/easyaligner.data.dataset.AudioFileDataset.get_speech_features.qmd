# get_speech_features { #easyaligner.data.dataset.AudioFileDataset.get_speech_features }

```python
data.dataset.AudioFileDataset.get_speech_features(
    audio_path,
    metadata,
    sr=16000,
)
```

Extract features for each speech segment in the metadata.

When `alignment_strategy` is `speech`, the speech segments are split into `chunk_size`
sized chunks for wav2vec2 inference.

## Parameters {.doc-section .doc-section-parameters}

+------------+---------------+-------------------------+------------+
| Name       | Type          | Description             | Default    |
+============+===============+=========================+============+
| audio_path | str           | Path to the audio file. | _required_ |
+------------+---------------+-------------------------+------------+
| metadata   | AudioMetadata | Metadata object.        | _required_ |
+------------+---------------+-------------------------+------------+
| sr         | int           | Sample rate.            | `16000`    |
+------------+---------------+-------------------------+------------+

## Returns {.doc-section .doc-section-returns}

+--------+--------------+---------------------------------------------------------------------------------+
| Name   | Type         | Description                                                                     |
+========+==============+=================================================================================+
|        | list of dict | List of dictionaries containing extracted features and metadata for each chunk. |
+--------+--------------+---------------------------------------------------------------------------------+